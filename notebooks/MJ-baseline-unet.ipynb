{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The notebook shows how to extract the segmentation map for the ships, augment the images and train a simple DNN model to detect them. A few additional tweaks like balancing the ship-count out a little better have been done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "We might want to adjust these later (or do some hyperparameter optimizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 30\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 400\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 200\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_PLOT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 2019-07-27 14:37:59 : Logging started\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "\n",
    "# Set level\n",
    "logger.setLevel(logging.INFO)\n",
    "#logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter\n",
    "FORMAT = \"%(levelno)-2s %(asctime)s : %(message)s\"\n",
    "DATE_FMT = \"%Y-%m-%d %H:%M:%S\"\n",
    "formatter = logging.Formatter(FORMAT, DATE_FMT)\n",
    "\n",
    "# Create handler and assign\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]\n",
    "logging.info(\"Logging started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Sci stack\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn\n",
    "from skimage.io import imread\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ship_dir = '../input'\n",
    "# train_image_dir = os.path.join(ship_dir, 'train_v2')\n",
    "# test_image_dir = os.path.join(ship_dir, 'test_v2')\n",
    "import gc; gc.enable() # memory is tight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set memory limit of TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "session = tf.Session(config=config)\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_session(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231723 masks found\n",
      "192556\n"
     ]
    }
   ],
   "source": [
    "DIR_INPUT = Path(r\"/notebooks/userdata/airbus\").expanduser()\n",
    "assert DIR_INPUT.exists()\n",
    "PATH_CSV = DIR_INPUT / 'train_ship_segmentations_v2.csv'\n",
    "assert PATH_CSV.exists()\n",
    "DIR_IMAGES = DIR_INPUT / 'train'\n",
    "assert DIR_IMAGES.exists()\n",
    "masks = pd.read_csv(PATH_CSV)\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "DIR_WEIGHTS = DIR_INPUT / 'weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "title": "Align the df with the actual sampled data"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 2019-07-27 14:38:14 : Resampled df to match existing images, 231723 records\n"
     ]
    }
   ],
   "source": [
    "masks\n",
    "DIR_IMAGES.joinpath('teas').exists()\n",
    "masks['exists'] = masks['ImageId'].apply(lambda image_id: DIR_IMAGES.joinpath(image_id).exists())\n",
    "# r = masks.head(10)\n",
    "masks = masks[masks['exists']]\n",
    "logging.info(\"Resampled df to match existing images, {} records\".format(len(masks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure encode/decode works\n",
    "Given the process\n",
    "$$  RLE_0 \\stackrel{Decode}{\\longrightarrow} \\textrm{Image}_0 \\stackrel{Encode}{\\longrightarrow} RLE_1 \\stackrel{Decode}{\\longrightarrow} \\textrm{Image}_1 $$\n",
    "We want to check if/that\n",
    "$ \\textrm{Image}_0 \\stackrel{?}{=} \\textrm{Image}_1 $\n",
    "We could check the RLEs as well but that is more tedious. Also depending on how the objects have been labeled we might have different counts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_PLOT:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "    rle_0 = masks.query('ImageId==\"00021ddc3.jpg\"')['EncodedPixels']\n",
    "    img_0 = masks_as_image(rle_0)\n",
    "    ax1.imshow(img_0[:, :, 0])\n",
    "    ax1.set_title('Image$_0$')\n",
    "    rle_1 = multi_rle_encode(img_0)\n",
    "    img_1 = masks_as_image(rle_1)\n",
    "    ax2.imshow(img_1[:, :, 0])\n",
    "    ax2.set_title('Image$_1$')\n",
    "    print('Check Decoding->Encoding',\n",
    "          'RLE_0:', len(rle_0), '->',\n",
    "          'RLE_1:', len(rle_1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and validation groups\n",
    "We stratify by the number of boats appearing so we have nice balances in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 2019-07-27 14:38:22 : Unique records: 191289\n",
      "20 2019-07-27 14:38:22 : Total records: 231723\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEcJJREFUeJzt3W+M3VWdx/H3dzsCFZXyx52QttmpsVlT7ao4gRrMZhZ2sYCxPEAXQ6Q1jX0gKG4mcctusmRVNpAsImzUbGO7gDFWRA2NrdvtFu6DfUChFaSUShix2jbFqi2w1Sg77Hcf3DPdS8+UuW3nzr3Teb+Smzm/8zu/e8/vO73zmd+fO43MRJKkVn/U7QlIknqP4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqRKX7cncLIuuOCCHBgY6PY0Ttpvf/tbzj777G5Po+usQ5N1sAZjOlmHHTt2/Doz39rO2GkbDgMDA2zfvr3b0zhpjUaDoaGhbk+j66xDk3WwBmM6WYeI+Hm7Yz2tJEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqTNtPSE9HA6s3Hm0PLx5lRctyp+25/eopey1J059HDpKkiuEgSaoYDpKkiuEgSaoYDpKkiuEgSaoYDpKkiuEgSaoYDpKkiuEgSaoYDpKkiuEgSaoYDpKkiuEgSaoYDpKkiuEgSaoYDpKkiuEgSaoYDpKkSlvhEBF/ExG7IuLpiPhWRJwVEQsiYltEjETEtyPijDL2zLI8UtYPtDzPLaX/2Yj4YEv/0tI3EhGrJ3snJUknZsJwiIi5wGeAwcx8FzALuA64A7grM98OHAZWlk1WAodL/11lHBGxqGz3TmAp8NWImBURs4CvAFcCi4CPlbGSpC5p97RSHzA7IvqANwIHgMuAB8v6+4BrSntZWaasvzwiovSvz8w/ZObPgBHg4vIYycznM/MVYH0ZK0nqkgnDITP3A/8M/IJmKLwE7ABezMzRMmwfMLe05wJ7y7ajZfz5rf3HbHO8fklSl/RNNCAizqX5m/wC4EXgOzRPC025iFgFrALo7++n0Wh0YxonbXjx6NF2/+zXLndar9bqyJEjPTu3qWQdrMGYXqnDhOEA/CXws8z8FUBEfA+4FJgTEX3l6GAesL+M3w/MB/aV01DnAL9p6R/Tus3x+l8jM9cAawAGBwdzaGiojen3jhWrNx5tDy8e5c6d7ZR/cuy5fmjKXutENBoNptv3sROsgzUY0yt1aOeawy+AJRHxxnLt4HLgGeAR4NoyZjnwUGlvKMuU9Q9nZpb+68rdTAuAhcBjwOPAwnL30xk0L1pvOPVdkySdrAl/dc3MbRHxIPAjYBR4guZv7xuB9RHxxdK3tmyyFvhGRIwAh2j+sCczd0XEAzSDZRS4MTNfBYiIm4DNNO+EWpeZuyZvFyVJJ6qt8xqZeStw6zHdz9O80+jYsb8HPnKc57kNuG2c/k3ApnbmIknqPD8hLUmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqtBUOETEnIh6MiJ9ExO6IeH9EnBcRWyLiufL13DI2IuKeiBiJiKci4qKW51lexj8XEctb+t8XETvLNvdEREz+rkqS2tXukcPdwL9n5juAdwO7gdXA1sxcCGwtywBXAgvLYxXwNYCIOA+4FbgEuBi4dSxQyphPtmy39NR2S5J0KiYMh4g4B/hzYC1AZr6SmS8Cy4D7yrD7gGtKexlwfzY9CsyJiAuBDwJbMvNQZh4GtgBLy7q3ZOajmZnA/S3PJUnqgr42xiwAfgX8W0S8G9gB3Az0Z+aBMuYFoL+05wJ7W7bfV/per3/fOP2ViFhF82iE/v5+Go1GG9PvHcOLR4+2+2e/drnTerVWR44c6dm5TSXrYA3G9Eod2gmHPuAi4NOZuS0i7ub/TyEBkJkZEdmJCR7zOmuANQCDg4M5NDTU6ZecVCtWbzzaHl48yp072yn/5Nhz/dCUvdaJaDQaTLfvYydYB2swplfq0M41h33AvszcVpYfpBkWvyynhChfD5b1+4H5LdvPK32v1z9vnH5JUpdMGA6Z+QKwNyL+tHRdDjwDbADG7jhaDjxU2huAG8pdS0uAl8rpp83AFRFxbrkQfQWwuax7OSKWlLuUbmh5LklSF7R7XuPTwDcj4gzgeeATNIPlgYhYCfwc+GgZuwm4ChgBflfGkpmHIuILwONl3Ocz81Bpfwq4F5gN/LA8JEld0lY4ZOaTwOA4qy4fZ2wCNx7nedYB68bp3w68q525SJI6z09IS5IqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqfe0OjIhZwHZgf2Z+KCIWAOuB84EdwMcz85WIOBO4H3gf8BvgrzNzT3mOW4CVwKvAZzJzc+lfCtwNzAK+npm3T9L+qRhYvbErr7vn9qu78rqSTs2JHDncDOxuWb4DuCsz3w4cpvlDn/L1cOm/q4wjIhYB1wHvBJYCX42IWSV0vgJcCSwCPlbGSpK6pK1wiIh5wNXA18tyAJcBD5Yh9wHXlPayskxZf3kZvwxYn5l/yMyfASPAxeUxkpnPZ+YrNI9Glp3qjkmSTl67p5W+DHwOeHNZPh94MTNHy/I+YG5pzwX2AmTmaES8VMbPBR5tec7WbfYe03/JeJOIiFXAKoD+/n4ajUab0+8Nw4tHj7b7Z792+XQ10ffoyJEj0+772AnWwRqM6ZU6TBgOEfEh4GBm7oiIoc5P6fgycw2wBmBwcDCHhro6nRO2ouW8//DiUe7c2fYln2lrz/VDr7u+0Wgw3b6PnWAdrMGYXqlDOz+dLgU+HBFXAWcBb6F58XhORPSVo4d5wP4yfj8wH9gXEX3AOTQvTI/1j2nd5nj9kqQumPCaQ2bekpnzMnOA5gXlhzPzeuAR4NoybDnwUGlvKMuU9Q9nZpb+6yLizHKn00LgMeBxYGFELIiIM8prbJiUvZMknZRTOa/xt8D6iPgi8ASwtvSvBb4RESPAIZo/7MnMXRHxAPAMMArcmJmvAkTETcBmmreyrsvMXacwL0nSKTqhcMjMBtAo7edp3ml07JjfAx85zva3AbeN078J2HQic5EkdY6fkJYkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVU7o/5CWTtTA6o2vu3548SgrJhhzsvbcfnVHnleaCTxykCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUmXCcIiI+RHxSEQ8ExG7IuLm0n9eRGyJiOfK13NLf0TEPRExEhFPRcRFLc+1vIx/LiKWt/S/LyJ2lm3uiYjoxM5KktrTzpHDKDCcmYuAJcCNEbEIWA1szcyFwNayDHAlsLA8VgFfg2aYALcClwAXA7eOBUoZ88mW7Zae+q5Jkk7WhOGQmQcy80el/d/AbmAusAy4rwy7D7imtJcB92fTo8CciLgQ+CCwJTMPZeZhYAuwtKx7S2Y+mpkJ3N/yXJKkLjihaw4RMQC8F9gG9GfmgbLqBaC/tOcCe1s221f6Xq9/3zj9kqQu6Wt3YES8Cfgu8NnMfLn1skBmZkRkB+Z37BxW0TxVRX9/P41Go9MvOamGF48ebffPfu3yTNXJOkynfx9HjhyZVvPtBGvQ1Ct1aCscIuINNIPhm5n5vdL9y4i4MDMPlFNDB0v/fmB+y+bzSt9+YOiY/kbpnzfO+EpmrgHWAAwODubQ0NB4w3rWitUbj7aHF49y5862s/m01ck67Ll+qCPP2wmNRoPp9u95slmDpl6pw4TvynLn0Fpgd2Z+qWXVBmA5cHv5+lBL/00RsZ7mxeeXSoBsBv6p5SL0FcAtmXkoIl6OiCU0T1fdAPzLJOzbcQ20/JCWJNXa+ZXtUuDjwM6IeLL0/R3NUHggIlYCPwc+WtZtAq4CRoDfAZ8AKCHwBeDxMu7zmXmotD8F3AvMBn5YHpKkLpkwHDLzv4Djfe7g8nHGJ3DjcZ5rHbBunP7twLsmmoskaWr4CWlJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRVDAdJUsVwkCRV+ro9AalTBlZv7Mrr7rn96q68rjSZPHKQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxQ/BSZPsZD58N7x4lBWn+KE9P3ynyeSRgySp0jPhEBFLI+LZiBiJiNXdno8kzWQ9cVopImYBXwH+CtgHPB4RGzLzme7OTJo+uvW3pMBTWqejnggH4GJgJDOfB4iI9cAywHCQpoHJCKaTue5iKHVOr5xWmgvsbVneV/okSV3QK0cObYmIVcCqsngkIp7t5nxOxWfgAuDX3Z5Ht1mHJutwcjWIOzo0me7q5L+FP2l3YK+Ew35gfsvyvNL3Gpm5BlgzVZPqpIjYnpmD3Z5Ht1mHJutgDcb0Sh165bTS48DCiFgQEWcA1wEbujwnSZqxeuLIITNHI+ImYDMwC1iXmbu6PC1JmrF6IhwAMnMTsKnb85hCp8XpsUlgHZqsgzUY0xN1iMzs9hwkST2mV645SJJ6iOHQARGxLiIORsTTLX3nRcSWiHiufD239EdE3FP+bMhTEXFR92Y+uSJifkQ8EhHPRMSuiLi59M+oWkTEWRHxWET8uNThH0v/gojYVvb32+VmDCLizLI8UtYPdHP+kykiZkXEExHxg7I842oAEBF7ImJnRDwZEdtLX0+9LwyHzrgXWHpM32pga2YuBLaWZYArgYXlsQr42hTNcSqMAsOZuQhYAtwYEYuYebX4A3BZZr4beA+wNCKWAHcAd2Xm24HDwMoyfiVwuPTfVcadLm4Gdrcsz8QajPmLzHxPy22rvfW+yEwfHXgAA8DTLcvPAheW9oXAs6X9r8DHxht3uj2Ah2j+/awZWwvgjcCPgEtoftCpr/S/H9hc2puB95d2XxkX3Z77JOz7PJo/9C4DfgDETKtBSy32ABcc09dT7wuPHKZOf2YeKO0XgP7SnhF/OqScFngvsI0ZWItyOuVJ4CCwBfgp8GJmjpYhrft6tA5l/UvA+VM74474MvA54H/L8vnMvBqMSeA/ImJH+csP0GPvi565lXUmycyMiBlzm1hEvAn4LvDZzHw5Io6umym1yMxXgfdExBzg+8A7ujylKRURHwIOZuaOiBjq9nx6wAcyc39E/DGwJSJ+0rqyF94XHjlMnV9GxIUA5evB0t/Wnw6ZriLiDTSD4ZuZ+b3SPSNrAZCZLwKP0DyFMicixn5Ba93Xo3Uo688BfjPFU51slwIfjog9wHqap5buZmbV4KjM3F++HqT5y8LF9Nj7wnCYOhuA5aW9nOb597H+G8odCUuAl1oOLae1aB4irAV2Z+aXWlbNqFpExFvLEQMRMZvmdZfdNEPi2jLs2DqM1eda4OEsJ5unq8y8JTPnZeYAzT+P83BmXs8MqsGYiDg7It481gauAJ6m194X3b4wczo+gG8BB4D/oXl+cCXN86VbgeeA/wTOK2OD5n909FNgJzDY7flPYh0+QPPc6lPAk+Vx1UyrBfBnwBOlDk8D/1D63wY8BowA3wHOLP1nleWRsv5t3d6HSa7HEPCDmVqDss8/Lo9dwN+X/p56X/gJaUlSxdNKkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqvwf+OQczEOCeqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "# some files are too small/corrupt\n",
    "masks['ImageId'].apply(lambda image_id: DIR_IMAGES.joinpath(image_id).exists())\n",
    "\n",
    "unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda image_id: os.stat(str(DIR_IMAGES.joinpath(image_id))).st_size/1024)\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "unique_img_ids['file_size_kb'].hist()\n",
    "# plt.show()\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)\n",
    "logging.info(\"Unique records: {}\".format(len(unique_img_ids)))\n",
    "logging.info(\"Total records: {}\".format(len(masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161048 training masks\n",
      "69034 validation masks\n"
     ]
    }
   ],
   "source": [
    "train_ids, valid_ids = train_test_split(unique_img_ids,\n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Number of Ship Images\n",
    "Here we examine how often ships appear and replace the ones without any ships with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe536140ba8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['ships'].hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef8115a80749ac47f295e9a70217a5553970c2b3"
   },
   "source": [
    "# Undersample Empty Images\n",
    "Here we undersample the empty images to get a better balanced group with more ships to try and segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 2019-07-27 14:38:23 : Balanced data frame with 11000 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     500\n",
       "1     955\n",
       "2     545\n",
       "3     840\n",
       "4     660\n",
       "5     795\n",
       "6     705\n",
       "7     784\n",
       "8     716\n",
       "9     834\n",
       "10    666\n",
       "11    779\n",
       "12    721\n",
       "13    467\n",
       "14    528\n",
       "15    505\n",
       "Name: ships, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\n",
    "def sample_ships(in_df, base_rep_val=1500):\n",
    "    if in_df['ships'].values[0]==0:\n",
    "        return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n",
    "    else:\n",
    "        return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n",
    "\n",
    "balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "balanced_train_df['ships'].hist(bins=np.arange(10))\n",
    "logging.info(\"Balanced data frame with {} records\".format(len(balanced_train_df)))\n",
    "# plt.show()\n",
    "balanced_train_df['ships'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode all the RLEs into Images\n",
    "We make a generator to produce batches of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = DIR_IMAGES / c_img_id\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (8, 768, 768, 3) 0.0 1.0\n",
      "y (8, 768, 768, 1) 0 1\n"
     ]
    }
   ],
   "source": [
    "train_gen = make_image_gen(balanced_train_df)\n",
    "# Get a single sample\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_PLOT:\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "    batch_rgb = montage_rgb(train_x)\n",
    "    batch_seg = montage(train_y[:, :, :, 0])\n",
    "    ax1.imshow(batch_rgb)\n",
    "    ax1.set_title('Images')\n",
    "    ax2.imshow(batch_seg)\n",
    "    ax2.set_title('Segmentations')\n",
    "    ax3.imshow(mark_boundaries(batch_rgb, \n",
    "                               batch_seg.astype(int)))\n",
    "    ax3.set_title('Outlined Ships')\n",
    "    plt.show()\n",
    "    # fig.savefig('overview.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 768, 768, 3) (400, 768, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "dg_args = dict(featurewise_center = False,\n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 15, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (8, 768, 768, 3) float32 0.0 1.0\n",
      "y (8, 768, 768, 1) float32 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "# only keep first 9 samples to examine in detail\n",
    "t_x = t_x[:9]\n",
    "t_y = t_y[:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_PLOT:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "    ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
    "    ax1.set_title('images')\n",
    "    ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n",
    "    ax2.set_title('ships')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Model\n",
    "Here we use a slight deviation on the U-Net standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "RGB_Input (InputLayer)          (None, 768, 768, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 768, 768, 3)  0           RGB_Input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 768, 768, 3)  12          gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 768, 768, 8)  224         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 768, 768, 8)  584         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 384, 384, 8)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 384, 384, 16) 1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 384, 384, 16) 2320        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 192, 192, 16) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 192, 192, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 192, 192, 32) 9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 96, 96, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 96, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 96, 64)   36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 48, 48, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 48, 48, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 48, 48, 128)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 96, 96, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96, 96, 192)  0           up_sampling2d[0][0]              \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 96, 96, 64)   110656      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 96, 96, 64)   36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 192, 192, 64) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192, 192, 96) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 192, 192, 32) 27680       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 192, 192, 32) 9248        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 384, 384, 32) 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 384, 384, 48) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 384, 384, 16) 6928        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 384, 384, 16) 2320        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 768, 768, 16) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 768, 768, 24) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 768, 768, 8)  1736        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 768, 768, 8)  584         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 768, 768, 1)  9           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 736, 736, 1)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 768, 768, 1)  0           cropping2d[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 491,149\n",
      "Trainable params: 491,143\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
    "\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return layers.UpSampling2D(strides)\n",
    "\n",
    "if UPSAMPLE_MODE=='DECONV':\n",
    "    upsample=upsample_conv\n",
    "else:\n",
    "    upsample=upsample_simple\n",
    "    \n",
    "input_img = layers.Input(t_x.shape[1:], name = 'RGB_Input')\n",
    "pp_in_layer = input_img\n",
    "if NET_SCALING is not None:\n",
    "    pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n",
    "    \n",
    "pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n",
    "pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
    "\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (pp_in_layer)\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = layers.MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = layers.MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = layers.MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = upsample(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = layers.concatenate([u6, c4])\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = upsample(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = layers.concatenate([u7, c3])\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = upsample(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = layers.concatenate([u8, c2])\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = upsample(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = layers.concatenate([u9, c1], axis=3)\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "d = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "if NET_SCALING is not None:\n",
    "    d = layers.UpSampling2D(NET_SCALING)(d)\n",
    "\n",
    "seg_model = models.Model(inputs=[input_img], outputs=[d])\n",
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 2019-07-27 14:39:00 : `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "weight_path = DIR_WEIGHTS / \"{}_weights.best.hdf5\".format('seg_model')\n",
    "weight_path = str(weight_path)\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential step size: 1375\n",
      "Actual steps per epoch: 200\n"
     ]
    }
   ],
   "source": [
    "print('Potential step size:', balanced_train_df.shape[0]//BATCH_SIZE)\n",
    "step_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0]//BATCH_SIZE)\n",
    "print('Actual steps per epoch:', step_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n",
    "loss_history = [seg_model.fit_generator(aug_gen, \n",
    "                             steps_per_epoch=step_count, \n",
    "                             epochs=NB_EPOCHS, \n",
    "                             validation_data=(valid_x, valid_y),\n",
    "                             callbacks=callbacks_list,\n",
    "                            workers=1 # the generator is not very thread safe\n",
    "                                       )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(loss_history):\n",
    "    epich = np.cumsum(np.concatenate(\n",
    "        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(22, 10))\n",
    "    _ = ax1.plot(epich,\n",
    "                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
    "                 'b-',\n",
    "                 epich, np.concatenate(\n",
    "            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "    ax1.legend(['Training', 'Validation'])\n",
    "    ax1.set_title('Loss')\n",
    "\n",
    "    _ = ax2.plot(epich, np.concatenate(\n",
    "        [mh.history['true_positive_rate'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_true_positive_rate'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax2.legend(['Training', 'Validation'])\n",
    "    ax2.set_title('True Positive Rate\\n(Positive Accuracy)')\n",
    "    \n",
    "    _ = ax3.plot(epich, np.concatenate(\n",
    "        [mh.history['binary_accuracy'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_binary_accuracy'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax3.legend(['Training', 'Validation'])\n",
    "    ax3.set_title('Binary Accuracy (%)')\n",
    "    \n",
    "    _ = ax4.plot(epich, np.concatenate(\n",
    "        [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_dice_coef'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax4.legend(['Training', 'Validation'])\n",
    "    ax4.set_title('DICE')\n",
    "\n",
    "show_loss(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce1167e9f09200f537e61f93f486168a13be1711"
   },
   "outputs": [],
   "source": [
    "seg_model.load_weights(weight_path)\n",
    "seg_model.save('seg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fe53610c198>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "275b411dc97a350aacaba46c8562efcf2658b1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 768, 768, 1) 0.0 0.0023689687 2.5622537e-08\n"
     ]
    }
   ],
   "source": [
    "pred_y = seg_model.predict(valid_x, batch_size=4)\n",
    "print(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y[50,:,:,0]\n",
    "pred_y[50,:,:,:].shape\n",
    "probs = pred_y[50,:,:,0].ravel()\n",
    "plt.hist(probs[probs > 0.1])\n",
    "#plt.hist(probs[probs > 0.1])\n",
    "plt.hist()\n",
    "pred_y[50,0,1]\n",
    "for i in range(10):\n",
    "    plt.imshow(pred_y[i,:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax.hist(pred_y.ravel(), np.linspace(0, 1, 10))\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale('log', nonposy='clip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Full Resolution Model\n",
    "Here we account for the scaling so everything can happen in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(seg_model)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = seg_model\n",
    "fullres_model.save('fullres_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(20, 2, figsize = (10, 40))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "for (ax1, ax2), c_img_name in zip(m_axs, test_paths):\n",
    "    c_path = os.path.join(test_image_dir, c_img_name)\n",
    "    c_img = imread(c_path)\n",
    "    first_img = np.expand_dims(c_img, 0)/255.0\n",
    "    first_seg = fullres_model.predict(first_img)\n",
    "    ax1.imshow(first_img[0])\n",
    "    ax1.set_title('Image')\n",
    "    ax2.imshow(first_seg[0, :, :, 0], vmin = 0, vmax = 1)\n",
    "    ax2.set_title('Prediction')\n",
    "fig.savefig('test_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11a6c6615131ff8c317f95a5097b46565ef21121"
   },
   "source": [
    "# Submission\n",
    "Since gneerating the submission takes a long time and quite a bit of memory we run it in a seperate kernel located at https://www.kaggle.com/kmader/from-trained-u-net-to-submission-part-2 \n",
    "That kernel takes the model saved in this kernel and applies it to all the test data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,_uuid,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
