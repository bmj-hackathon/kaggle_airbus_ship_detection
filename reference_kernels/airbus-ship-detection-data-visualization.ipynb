{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18c735c4a3e7d53bbcd82dfd676240301cb075e0"
   },
   "source": [
    "**<h2>Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d30127c5abec33501bff60055ab83187a546a5c6"
   },
   "source": [
    "In this notebook, I try to explore the Airbus Ship Detection Challenge data and get some sense of what types of features may be useful. This is work in progress, so i will keep updating it. I hope you find this helpful. Happy Kaggling :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f926376d1380568f248346353c42fcf599e6c0e6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel,threshold_otsu, threshold_niblack,threshold_sauvola\n",
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from scipy import signal\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import os \n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8d19639fac647b9933ba36071a63ea26a638416"
   },
   "source": [
    "<h2> Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DATA_PATH'] = '../input'\n",
    "INPUT_PATH = Path(os.environ['DATA_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/media/batman/f4023177-48c1-456b-bff2-cc769f3ac277/DATA/airbus-ship-detection\")\n",
    "assert data_path.exists()\n",
    "img_zip_path = data_path / 'train_v2.zip'\n",
    "assert img_zip_path.exists()\n",
    "record_path = data_path / 'train_ship_segmentations_v2.csv'\n",
    "assert record_path.exists()\n",
    "\n",
    "img_zip = zipfile.ZipFile(img_zip_path)\n",
    "\n",
    "df = pd.read_csv(record_path)\n",
    "df = df.set_index('ImageId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f1a78c7e479a65719964c9536298f82afb969ebf"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../input/train_ship_segmentations.csv' does not exist: b'../input/train_ship_segmentations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c305317d4c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTRAIN_MASKS_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/masks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTEST_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train_ship_segmentations.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpath_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/train/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpath_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/test/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle_airbus_ship_detection--XF7Jji-/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle_airbus_ship_detection--XF7Jji-/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle_airbus_ship_detection--XF7Jji-/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle_airbus_ship_detection--XF7Jji-/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle_airbus_ship_detection--XF7Jji-/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/train_ship_segmentations.csv' does not exist: b'../input/train_ship_segmentations.csv'"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = '../input'\n",
    "DATA_PATH = INPUT_PATH\n",
    "TRAIN_DATA = os.path.join(DATA_PATH, \"train\")\n",
    "TRAIN_MASKS_DATA = os.path.join(DATA_PATH, \"train/masks\")\n",
    "TEST_DATA = os.path.join(DATA_PATH, \"test\")\n",
    "df = pd.read_csv(DATA_PATH+'/train_ship_segmentations.csv')\n",
    "path_train = '../input/train/'\n",
    "path_test = '../input/test/'\n",
    "train_ids = df.ImageId.values\n",
    "df = df.set_index('ImageId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62f821d9d4a7bf8530d6478f2a14f35919f44cc9"
   },
   "source": [
    "<h2> Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b9447b5a9c6369010e3f949ec741def0687a139a"
   },
   "outputs": [],
   "source": [
    "def get_filename(image_id, image_type):\n",
    "    check_dir = False\n",
    "    if \"Train\" == image_type:\n",
    "        data_path = TRAIN_DATA\n",
    "    elif \"mask\" in image_type:\n",
    "        data_path = TRAIN_MASKS_DATA\n",
    "    elif \"Test\" in image_type:\n",
    "        data_path = TEST_DATA\n",
    "    else:\n",
    "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
    "\n",
    "    if check_dir and not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    return os.path.join(data_path, \"{}\".format(image_id))\n",
    "\n",
    "def get_image_data(image_id, image_type, **kwargs):\n",
    "    img = _get_image_data_opencv(image_id, image_type, **kwargs)\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "def _get_image_data_opencv(image_id, image_type, **kwargs):\n",
    "    fname = get_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "# https://github.com/ternaus/TernausNet/blob/master/Example.ipynb\n",
    "def mask_overlay(image, mask):\n",
    "    \"\"\"\n",
    "    Helper function to visualize mask\n",
    "    \"\"\"\n",
    "    mask = mask.astype(np.uint8)\n",
    "    weighted_sum = cv2.addWeighted(mask, 0.75, image, 0.5, 0.)\n",
    "    img = image.copy()\n",
    "    ind = mask[:, :, 1] > 0    \n",
    "    img[ind] = weighted_sum[ind]    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "338497fc51d3a8876a67ff056faaa9de1f2e61b7"
   },
   "source": [
    "<h2>**Plotting Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb586a4d1e99e575880aafcb3a04c683e95253ba"
   },
   "source": [
    "Lets plot some random images from training set and then few more images with the mask overlayed on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "12a555948195593dde1bfaf38c48946e1c046ae3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6195fd01fa31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ImageId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0m_train_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_train_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# _train_ids = _train_ids[:nImg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ids' is not defined"
     ]
    }
   ],
   "source": [
    "nImg = 32  #no. of images that you want to display\n",
    "np.random.seed(42)\n",
    "if df.index.name == 'ImageId':\n",
    "    df = df.reset_index()\n",
    "if df.index.name != 'ImageId':\n",
    "    df = df.set_index('ImageId')\n",
    "    \n",
    "_train_ids = list(train_ids)\n",
    "np.random.shuffle(_train_ids)\n",
    "# _train_ids = _train_ids[:nImg]\n",
    "tile_size = (256, 256)\n",
    "n = 8\n",
    "alpha = 0.3\n",
    "\n",
    "# m = int(np.ceil(len(_train_ids) * 1.0 / n))\n",
    "m = int(np.ceil(nImg * 1.0 / n))\n",
    "complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "complete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "\n",
    "counter = 0\n",
    "for i in range(m):\n",
    "    ys = i*(tile_size[1] + 2)\n",
    "    ye = ys + tile_size[1]\n",
    "    j = 0\n",
    "    while j < n:\n",
    "        counter += 1\n",
    "        all_masks = np.zeros((768, 768))\n",
    "        xs = j*(tile_size[0] + 2)\n",
    "        xe = xs + tile_size[0]\n",
    "        image_id = _train_ids[counter]\n",
    "        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n",
    "            continue\n",
    "        else:\n",
    "            j += 1\n",
    "        img = get_image_data(image_id, 'Train')\n",
    "        \n",
    "        try:\n",
    "            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n",
    "            for mask in img_masks:\n",
    "                all_masks += rle_decode(mask)\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n",
    "            \n",
    "            img_masked = mask_overlay(img, all_masks)\n",
    "            \n",
    "#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "\n",
    "        except Exception as e:\n",
    "            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)*255\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n",
    "            \n",
    "            img_masked = mask_overlay(img, all_masks)        \n",
    "#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n",
    "\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "#             pdb.set_trace()\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "\n",
    "        \n",
    "m = complete_image.shape[0] / (tile_size[0] + 2)\n",
    "k = 8\n",
    "n = int(np.ceil(m / k))\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ys = i*(tile_size[0] + 2)*k\n",
    "    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n",
    "    plt.imshow(complete_image[ys:ye,:,:],cmap='seismic')\n",
    "    plt.title(\"Training dataset\")\n",
    "    \n",
    "m = complete_image.shape[0] / (tile_size[0] + 2)\n",
    "k = 8\n",
    "n = int(np.ceil(m / k))\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ys = i*(tile_size[0] + 2)*k\n",
    "    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n",
    "    plt.imshow(complete_image_masked[ys:ye,:,:])\n",
    "    plt.title(\"Training dataset: Lighter Color depicts ship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "047aa6fe7ae4fd071a44878d8386235563165096"
   },
   "source": [
    "<h3>Plotting Ship Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "391141f3290c383db2ebfb6e136824d93ac6cad2"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df['ship_count'] = df.groupby('ImageId')['ImageId'].transform('count')\n",
    "df.loc[df['EncodedPixels'].isnull().values,'ship_count'] = 0  #see infocusp's comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4446af7ccc322df5a06b56ecfa0e6cb6fba08e1c"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.distplot(df['ship_count'],kde=False)\n",
    "plt.title('Ship Count Distribution in Train Set')\n",
    "\n",
    "print(df['ship_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9bb024c87ee036619a3215a00fbe9df69725daf"
   },
   "source": [
    "<h2>**Plotting Images: Based on Ship Count**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "397b7202a0106ee3e944124d2371e560bcc60ac9"
   },
   "source": [
    "Let's plot some images having different ship counts and try to see if we are able to glean any differences. This way, we can get some sense of what we're looking at. The images are 768 x 768 pixels each with the mask (in lighter color) overlayed on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "463cde8d66d9270f1bb9ce37d2522865955dd6e9"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f97b4278913da6c803137209d7fbf872b5356aa6"
   },
   "source": [
    "<h2> Training Set Images with Ship Count 0 i.e. no ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "5914bed1386a5c1ada8e131b26f0e7b1e1643f9c"
   },
   "outputs": [],
   "source": [
    "nImg = 32  #no. of images that you want to display\n",
    "np.random.seed(42)\n",
    "if df.index.name == 'ImageId':\n",
    "    df = df.reset_index()\n",
    "if df.index.name != 'ImageId':\n",
    "    df = df.set_index('ImageId')\n",
    "    \n",
    "_train_ids = list(train_ids)\n",
    "# _train_ids = list(train_ids[idx])\n",
    "np.random.shuffle(_train_ids)\n",
    "# _train_ids = _train_ids[:nImg]\n",
    "tile_size = (256, 256)\n",
    "n = 8\n",
    "alpha = 0.4\n",
    "\n",
    "# m = int(np.ceil(len(_train_ids) * 1.0 / n))\n",
    "m = int(np.ceil(nImg * 1.0 / n))\n",
    "complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "complete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "\n",
    "counter = 0\n",
    "for i in range(m):\n",
    "    ys = i*(tile_size[1] + 2)\n",
    "    ye = ys + tile_size[1]\n",
    "    j = 0\n",
    "    while j < n:\n",
    "        counter += 1\n",
    "\n",
    "        all_masks = np.zeros((768, 768))\n",
    "        xs = j*(tile_size[0] + 2)\n",
    "        xe = xs + tile_size[0]\n",
    "        image_id = _train_ids[counter]\n",
    "        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n",
    "            j += 1            \n",
    "        else:\n",
    "            continue\n",
    "        img = get_image_data(image_id, 'Train')\n",
    "        img = cv2.resize(img, dsize=tile_size)\n",
    "        img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "        complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "\n",
    "\n",
    "    \n",
    "m = complete_image.shape[0] / (tile_size[0] + 2)\n",
    "k = 8\n",
    "n = int(np.ceil(m / k))\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ys = i*(tile_size[0] + 2)*k\n",
    "    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n",
    "    plt.imshow(complete_image[ys:ye,:,:])\n",
    "    plt.title(\"Training Set Ship Count 0 i.e. no ship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db0cda6094b801e15ea39a4fbd9defd471c0b18b"
   },
   "source": [
    "<h2> Training Set Images with Ship Count between 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d9d0e4e1615fa710d5ecf8b79a80a8c874e61e6f"
   },
   "outputs": [],
   "source": [
    "nImg = 32  #no. of images that you want to display\n",
    "np.random.seed(42)\n",
    "idx = np.ravel(np.where((df['ship_count']<6) ) )\n",
    "if df.index.name == 'ImageId':\n",
    "    df = df.reset_index()\n",
    "_train_ids = list(df.loc[idx,'ImageId'])\n",
    "if df.index.name != 'ImageId':\n",
    "    df = df.set_index('ImageId')\n",
    "\n",
    "np.random.shuffle(_train_ids)\n",
    "\n",
    "tile_size = (256, 256)\n",
    "n = 8\n",
    "alpha = 0.4\n",
    "\n",
    "m = int(np.ceil(nImg * 1.0 / n))\n",
    "complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "complete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "\n",
    "counter = 0\n",
    "for i in range(m):\n",
    "    ys = i*(tile_size[1] + 2)\n",
    "    ye = ys + tile_size[1]\n",
    "    j = 0\n",
    "    while j < n:\n",
    "        counter += 1\n",
    "        all_masks = np.zeros((768, 768))\n",
    "        xs = j*(tile_size[0] + 2)\n",
    "        xe = xs + tile_size[0]\n",
    "        image_id = _train_ids[counter]\n",
    "        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n",
    "            continue\n",
    "        else:\n",
    "            j += 1\n",
    "        img = get_image_data(image_id, 'Train')\n",
    "        \n",
    "        try:\n",
    "            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n",
    "            for mask in img_masks:\n",
    "                all_masks += rle_decode(mask)\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n",
    "            \n",
    "            img_masked = mask_overlay(img, all_masks)\n",
    "#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n",
    "\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "\n",
    "        except Exception as e:\n",
    "            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)*255\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n",
    "        \n",
    "#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "            img_masked = mask_overlay(img, all_masks)\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "    \n",
    "m = complete_image.shape[0] / (tile_size[0] + 2)\n",
    "k = 8\n",
    "n = int(np.ceil(m / k))\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ys = i*(tile_size[0] + 2)*k\n",
    "    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n",
    "    plt.imshow(complete_image_masked[ys:ye,:,:])\n",
    "    plt.title(\"Training Set Ship Count 1 to 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4482ec8bee847dd75b53e0be48cff362e0117d1"
   },
   "source": [
    "<h2> Training Set Images with Ship Count 5 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "66e5add359a991ac2659f836be305c8a7d8dadd9"
   },
   "outputs": [],
   "source": [
    "nImg = 32  #no. of images that you want to display\n",
    "np.random.seed(42)\n",
    "idx = np.ravel(np.where((df['ship_count']<11) & (df['ship_count']>5)) )\n",
    "if df.index.name == 'ImageId':\n",
    "    df = df.reset_index()\n",
    "_train_ids = list(df.loc[idx,'ImageId'])\n",
    "if df.index.name != 'ImageId':\n",
    "    df = df.set_index('ImageId')\n",
    "\n",
    "np.random.shuffle(_train_ids)\n",
    "\n",
    "tile_size = (256, 256)\n",
    "n = 8\n",
    "alpha = 0.4\n",
    "\n",
    "m = int(np.ceil(nImg * 1.0 / n))\n",
    "complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "complete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "\n",
    "counter = 0\n",
    "for i in range(m):\n",
    "    ys = i*(tile_size[1] + 2)\n",
    "    ye = ys + tile_size[1]\n",
    "    j = 0\n",
    "    while j < n:\n",
    "        counter += 1\n",
    "        all_masks = np.zeros((768, 768))\n",
    "        xs = j*(tile_size[0] + 2)\n",
    "        xe = xs + tile_size[0]\n",
    "        image_id = _train_ids[counter]\n",
    "        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n",
    "            continue\n",
    "        else:\n",
    "            j += 1\n",
    "        img = get_image_data(image_id, 'Train')\n",
    "        \n",
    "        try:\n",
    "            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n",
    "            for mask in img_masks:\n",
    "                all_masks += rle_decode(mask)\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n",
    "            \n",
    "            img_masked = mask_overlay(img, all_masks)\n",
    "#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n",
    "\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "\n",
    "        except Exception as e:\n",
    "            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)*255\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n",
    "        \n",
    "            img_masked = mask_overlay(img, all_masks)\n",
    "#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "    \n",
    "m = complete_image.shape[0] / (tile_size[0] + 2)\n",
    "k = 8\n",
    "n = int(np.ceil(m / k))\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ys = i*(tile_size[0] + 2)*k\n",
    "    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n",
    "    plt.imshow(complete_image_masked[ys:ye,:,:])\n",
    "    plt.title(\"Training Set Ship Count 5 to 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f4e82596ddabec29b9c5a62bc6533e2b9adb28a"
   },
   "source": [
    "<h2>Training Set Images with Ship Count greater than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2977babea3db6b65cb3a3942e136e18a4873101f"
   },
   "outputs": [],
   "source": [
    "nImg = 32  #no. of images that you want to display\n",
    "np.random.seed(42)\n",
    "idx = np.ravel(np.where((df['ship_count']>10) ) )\n",
    "if df.index.name == 'ImageId':\n",
    "    df = df.reset_index()\n",
    "_train_ids = list(df.loc[idx,'ImageId'])\n",
    "if df.index.name != 'ImageId':\n",
    "    df = df.set_index('ImageId')\n",
    "# _train_ids = list(train_ids[idx])\n",
    "np.random.shuffle(_train_ids)\n",
    "# _train_ids = _train_ids[:nImg]\n",
    "tile_size = (256, 256)\n",
    "n = 8\n",
    "alpha = 0.4\n",
    "\n",
    "m = int(np.ceil(nImg * 1.0 / n))\n",
    "complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "complete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
    "\n",
    "counter = 0\n",
    "for i in range(m):\n",
    "    ys = i*(tile_size[1] + 2)\n",
    "    ye = ys + tile_size[1]\n",
    "    j = 0\n",
    "    while j < n:\n",
    "        counter += 1\n",
    "        all_masks = np.zeros((768, 768))\n",
    "        xs = j*(tile_size[0] + 2)\n",
    "        xe = xs + tile_size[0]\n",
    "        image_id = _train_ids[counter]\n",
    "        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n",
    "            continue\n",
    "        else:\n",
    "            j += 1\n",
    "        img = get_image_data(image_id, 'Train')\n",
    "        \n",
    "        try:\n",
    "            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n",
    "            for mask in img_masks:\n",
    "                all_masks += rle_decode(mask)\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n",
    "            \n",
    "            img_masked = mask_overlay(img, all_masks)\n",
    "#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "            \n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "#             pdb.set_trace()\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "        except Exception as e:\n",
    "#             print(e,counter)\n",
    "            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n",
    "            all_masks = np.expand_dims(all_masks,axis=2)*255\n",
    "            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n",
    "        \n",
    "            img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n",
    "    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n",
    "\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            img_masked = cv2.resize(img_masked, dsize=tile_size)\n",
    "\n",
    "            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n",
    "#             pdb.set_trace()\n",
    "\n",
    "            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n",
    "            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n",
    "    \n",
    "m = complete_image.shape[0] / (tile_size[0] + 2)\n",
    "k = 8\n",
    "n = int(np.ceil(m / k))\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ys = i*(tile_size[0] + 2)*k\n",
    "    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n",
    "    plt.imshow(complete_image_masked[ys:ye,:,:])\n",
    "    plt.title(\"Training Set Ship Count greater than 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1b6e6add8ac352017f60b2e9bf401355b8977d94",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes too long.. have to optimize it\n",
    "# # _train_ids = list(df_train.loc[count_idx[0],'id']+'.png')\n",
    "\n",
    "# idx = np.ravel(np.where((df['ship_count']<6) & (df['ship_count']>1)) )\n",
    "# if df.index.name == 'ImageId':\n",
    "#     df = df.reset_index()\n",
    "# _train_ids1 = list(df.loc[idx,'ImageId'])\n",
    "\n",
    "# idx = np.ravel(np.where((df['ship_count']<11) & (df['ship_count']>5)) )\n",
    "# _train_ids2 = list(df.loc[idx,'ImageId'])\n",
    "\n",
    "# idx = np.ravel(np.where((df['ship_count']>10) ) )\n",
    "# _train_ids3 = list(df.loc[idx,'ImageId'])\n",
    "# df = df.set_index('ImageId')\n",
    "\n",
    "# # takes a long time...\n",
    "# # mask_count1 = np.zeros((768, 768,len(_train_ids1)), dtype=np.float32)\n",
    "# # for n, id_ in tqdm(enumerate(_train_ids1), total=len(_train_ids1)):\n",
    "# #     image_id = _train_ids1[n]\n",
    "# #     img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n",
    "# #     all_masks = np.zeros((768, 768))\n",
    "# #     for mask in img_masks:\n",
    "# #         all_masks += rle_decode(mask)\n",
    "# #     mask_count1[:,:,n] = (all_masks>0).astype('uint8')\n",
    "\n",
    "# # mean_mask_count1 = mask_count1.mean(axis=2)\n",
    "# # del mask_count1\n",
    "\n",
    "# mask_count2 = np.zeros((768, 768,len(_train_ids2)), dtype=np.float32)\n",
    "# for n, id_ in tqdm(enumerate(_train_ids2), total=len(_train_ids2)):\n",
    "#     image_id = _train_ids2[n]\n",
    "#     img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n",
    "#     all_masks = np.zeros((768, 768))\n",
    "#     for mask in img_masks:\n",
    "#         all_masks += rle_decode(mask)\n",
    "#     mask_count2[:,:,n] = (all_masks>0).astype('uint8')\n",
    "\n",
    "# mean_mask_count2 = mask_count2.mean(axis=2)\n",
    "# del mask_count2\n",
    "\n",
    "# mask_count3 = np.zeros((768, 768,len(_train_ids3)), dtype=np.float32)\n",
    "# for n, id_ in tqdm(enumerate(_train_ids3), total=len(_train_ids3)):\n",
    "#     image_id = _train_ids3[n]\n",
    "#     img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n",
    "#     all_masks = np.zeros((768, 768))\n",
    "#     for mask in img_masks:\n",
    "#         all_masks += rle_decode(mask)\n",
    "#     mask_count3[:,:,n] = (all_masks>0).astype('uint8')\n",
    "\n",
    "# mean_mask_count3 = mask_count3.mean(axis=2)\n",
    "# del mask_count3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0a03afddb7f102138cb09d3e6e79989d2a851f21",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(1,figsize=(30,15))\n",
    "\n",
    "# # ax = fig.add_subplot(1,3,1)\n",
    "# # ax.imshow(mean_mask_count1)\n",
    "# # ax.set_title(\"Ship Location for Count: 0 to 5\")\n",
    "\n",
    "# ax = fig.add_subplot(1,2,1)\n",
    "# ax.imshow(mean_mask_count2)\n",
    "# ax.set_title(\"Ship Location for Count: 5 to 10\")\n",
    "\n",
    "# ax = fig.add_subplot(1,2,2)\n",
    "# ax.imshow(mean_mask_count3)\n",
    "# ax.set_title(\"Ship Location for Count: 5 to 10\")\n",
    "\n",
    "# plt.suptitle('Mean Masks for different s',y=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "730aaf122a1e26e85f339dcd48d5cbe02f072529"
   },
   "source": [
    "**<h2>Transforming the Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fc5f26b5732e9fde19373693f6f9020553e991f"
   },
   "source": [
    "Let's try to transform the images in some way to enhance the contrast between the ship and the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2cc9558e03b0da2a6893182d5e9b72e591964117"
   },
   "source": [
    "<h3>**Smoothing the Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1fbefd0c66cbfbf2609a05eff6dbcd8aa40af28",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian,laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "63604095e13f6121891daff222e589dfc6680a3f"
   },
   "outputs": [],
   "source": [
    "_train_ids = list(train_ids)\n",
    "fig = plt.figure(1,figsize=(15,15))\n",
    "for i in range(9):\n",
    "    image_id = _train_ids[np.random.randint(0,len(_train_ids))]\n",
    "    ax = fig.add_subplot(3,3,i+1)\n",
    "    img = get_image_data(image_id, 'Train')\n",
    "    img = gaussian(img)\n",
    "    img = cv2.resize(img, dsize=tile_size)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title('Smoothed Image')\n",
    "    \n",
    "plt.show()\n",
    "plt.suptitle('Smoothed Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "729250fbe0ba64e10df5318655e70147e5e1b39d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import canny\n",
    "from skimage.filters import scharr\n",
    "from skimage import exposure\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9decd70b744e36866a42fbc91f876fddd4be22a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@adapt_rgb(hsv_value)\n",
    "def canny_hsv(image):\n",
    "    return canny(image)\n",
    "\n",
    "@adapt_rgb(hsv_value)\n",
    "def scharr_hsv(image):\n",
    "    return scharr(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a27a8ccc5cad45f7479b825b698e105c3c8062ab"
   },
   "source": [
    "<h2> Extracting some useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c871dc640f824a9e6f971ce92a3cee094f03c9f4"
   },
   "outputs": [],
   "source": [
    "# simple features that can be easily extracted and used for training deep networks\n",
    "# these features may be used along with original image\n",
    "np.random.seed(13)\n",
    "# random.seed(12)\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.subplots_adjust(bottom=0.2, top=1.2)  #adjust this to change vertical and horiz. spacings..\n",
    "nImg = 5  #no. of images to process\n",
    "j = 0\n",
    "for _ in range(nImg):\n",
    "    q = j+1\n",
    "    image_id = _train_ids[np.random.randint(0,len(_train_ids))]\n",
    "    ax = fig.add_subplot(3,3,i+1)\n",
    "    img = get_image_data(image_id, 'Train')\n",
    "    \n",
    "#     # Contrast stretching\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    \n",
    "    # Equalization\n",
    "    img_eq = exposure.equalize_hist(img)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    img_adapteq = exposure.equalize_adapthist(img)\n",
    "    \n",
    "    edge_scharr = scharr_hsv(img)\n",
    "    edge_canny = canny_hsv(img)\n",
    "\n",
    "    \n",
    "    plt.subplot(nImg,8,q*8-7)\n",
    "    plt.imshow(img, cmap='binary')\n",
    "    plt.title('Original Image')\n",
    "    \n",
    "    plt.subplot(nImg,8,q*8-6)\n",
    "    plt.imshow(img, cmap='binary')\n",
    "    plt.title('Image Mask')\n",
    "    \n",
    "    plt.subplot(nImg,8,q*8-5)    \n",
    "    plt.imshow(img_rescale, cmap='binary')\n",
    "    plt.title('Contrast stretching')\n",
    "    \n",
    "    plt.subplot(nImg,8,q*8-4)\n",
    "    plt.imshow(img_eq, cmap='binary')\n",
    "    plt.title('Equalization')\n",
    "    \n",
    "    plt.subplot(nImg,8,q*8-3)\n",
    "    plt.imshow(img_adapteq, cmap='binary')\n",
    "    plt.title('Adaptive Equalization')\n",
    "    \n",
    "    plt.subplot(nImg,8,q*8-2)\n",
    "    plt.imshow(edge_scharr, cmap='binary')\n",
    "    plt.title('Scharr Edge Magnitude')\n",
    "    \n",
    "    plt.subplot(nImg,8,q*8-1)\n",
    "    plt.imshow(edge_canny, cmap='binary')\n",
    "    plt.title('Canny features')\n",
    "    j = j + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2154b1c5e56d5459e8d52c5a4d46e874faeab315",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_airbus_ships",
   "language": "python",
   "name": "kaggle_airbus_ships"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
